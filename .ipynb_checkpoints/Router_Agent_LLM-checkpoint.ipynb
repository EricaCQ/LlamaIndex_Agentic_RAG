{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414158b1-99d2-4524-b498-dc59bbbc8b55",
   "metadata": {},
   "source": [
    "# Router Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee70913-291f-4c9f-ad4a-79193cfee8cb",
   "metadata": {},
   "source": [
    "#### This notebook presents reproduces a cookbook for a Router Engine applying a Q&A to a pdf file via Sumamry Query Engine.  \n",
    "#### Source: Original classes and https://learn.deeplearning.ai/courses/building-agentic-rag-with-llamaindex/lesson/2/router-query-engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c43a04d-cc1e-4336-82a2-73ee45b4e653",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b11d3c-6729-4a9e-ab21-580467b5a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106d95fd-3498-4bcf-8dd7-2c54ba4f4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f3b2d0-a6ae-40e4-bbd5-49d2b6f455a6",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9b9433-c38b-499c-99f8-b2f38986361c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-09 22:50:20--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
      "Resolvendo openreview.net (openreview.net)... 35.184.86.251\n",
      "Conectando-se a openreview.net (openreview.net)|35.184.86.251|:443... conectado.\n",
      "A requisição HTTP foi enviada, aguardando resposta... 200 OK\n",
      "Tamanho: 16911937 (16M) [application/pdf]\n",
      "Salvando em: “metagpt.pdf”\n",
      "\n",
      "metagpt.pdf         100%[===================>]  16,13M  9,62MB/s    em 1,7s    \n",
      "\n",
      "2024-05-09 22:50:23 (9,62 MB/s) - “metagpt.pdf” salvo [16911937/16911937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab050c0-8473-45b0-b753-29f6aea58546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc77069-7a94-4419-a0dc-1e1cfc265789",
   "metadata": {},
   "source": [
    "## Define LLM and Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb917e3-f166-4868-a2a1-a1a08b8513c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5bf8f72-c53a-49dc-96c6-d742c940580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca6d43-6c81-4661-9039-75ac74462986",
   "metadata": {},
   "source": [
    "## Define Summary Index and Vector Index over the Same Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ed0a1f-1846-45dc-8e7a-95fc832693f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa1032-20e0-4076-b3ec-e0859afae992",
   "metadata": {},
   "source": [
    "## Define Query Engines and Set Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46245d7c-8d71-4b32-995e-0230a6df01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0876717-7762-473a-b33c-d41b0ec89b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e1fdb-1a31-48dd-90c3-dc1969f1f3b6",
   "metadata": {},
   "source": [
    "## Define Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "606f714f-f901-41e0-8333-5cc3ee41c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5027576-d97d-47f9-aec1-72755de17ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001b[0mThe document introduces MetaGPT, a meta-programming framework that enhances multi-agent collaboration based on Large Language Models (LLMs) by incorporating human-like Standardized Operating Procedures (SOPs). MetaGPT aims to streamline workflows by assigning specific roles to agents, breaking down complex tasks into subtasks, and ensuring structured communication among agents. It emphasizes the importance of role specialization, workflow efficiency, and executable feedback mechanisms to improve code generation quality. The framework achieves state-of-the-art performance in evaluations and offers a promising approach for developing LLM-based multi-agent systems with enhanced robustness and efficiency. Additionally, the document discusses the software development process using MetaGPT, highlighting the structured workflow involving different agents like Product Managers, Architects, Engineers, and QA Engineers to generate functional applications. It also evaluates MetaGPT's performance compared to other AI models in generating executable code based on clear requirements and structured messaging. The document further explores the performance evaluation of GPT models, ethical concerns related to AI systems, challenges addressed by MetaGPT, and provides examples of tasks from the SoftwareDev dataset with statistics on code, documentation, cost, and code executability.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62bcc36a-e4a6-4a11-9795-a06e9a2d7e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d008ef25-7868-4172-b06d-f5f17a642ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it focuses on retrieving specific context from the MetaGPT paper, which may provide insights into how agents share information with other agents..\n",
      "\u001b[0mAgents share information with other agents by utilizing a shared message pool. This shared message pool allows all agents to exchange messages directly. Agents publish their structured messages in the pool and can also access messages from other entities transparently. This system enables any agent to retrieve necessary information directly from the shared pool without having to inquire about other agents and wait for their responses, ultimately enhancing communication efficiency.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How do agents share information with other agents?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6760d9-d1ff-42b5-af40-1afadbb05994",
   "metadata": {},
   "source": [
    "## Calling Router Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dada66e-7e11-4b31-ae78-e30a466c2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_router_query_engine\n",
    "\n",
    "query_engine = get_router_query_engine(\"metagpt.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3f157c-3fb8-4e9e-8cd4-ec1dc892e4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The ablation study results are specific context from the MetaGPT paper, making choice 2 the most relevant..\n",
      "\u001b[0mThe ablation study results demonstrate the effectiveness of MetaGPT in addressing challenges related to information overload and reducing hallucinations in software generation tasks. By utilizing a global message pool and a subscription mechanism, MetaGPT successfully manages excessive or irrelevant information, ensuring efficiency in communication and enhancing the relevance and utility of the information provided. This design approach is crucial in optimizing the performance of the system and improving the quality of generated software programs.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49551aa2-cb1b-4a9e-8c72-ec37e0767083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
